// claude-symphony AI Benchmarking Configuration
{
  "benchmarking": {
    "enabled": true,
    "description": "AI model performance comparison and optimal model dynamic selection",
    "enabled_stages": [
      "06-implementation",
      "07-refactoring",
      "09-testing"
    ],
    "benchmark_tasks": {
      "code_generation": {
        "description": "Code generation quality comparison",
        "models": [
          "claude",
          "codex"
        ],
        "metrics": [
          {
            "name": "correctness",
            "weight": 0.4,
            "measure": "test_pass_rate"
          },
          {
            "name": "performance",
            "weight": 0.2,
            "measure": "execution_time"
          },
          {
            "name": "style_compliance",
            "weight": 0.2,
            "measure": "lint_score"
          },
          {
            "name": "readability",
            "weight": 0.2,
            "measure": "complexity_score"
          }
        ]
      },
      "refactoring": {
        "description": "Refactoring quality comparison",
        "models": [
          "codex",
          "claude"
        ],
        "metrics": [
          {
            "name": "complexity_reduction",
            "weight": 0.3,
            "measure": "cyclomatic_complexity_delta"
          },
          {
            "name": "test_coverage",
            "weight": 0.3,
            "measure": "coverage_percentage"
          },
          {
            "name": "performance_improvement",
            "weight": 0.2,
            "measure": "benchmark_time_delta"
          },
          {
            "name": "maintainability",
            "weight": 0.2,
            "measure": "maintainability_index"
          }
        ]
      },
      "test_generation": {
        "description": "Test code generation comparison",
        "models": [
          "codex",
          "claude"
        ],
        "metrics": [
          {
            "name": "coverage",
            "weight": 0.4,
            "measure": "line_coverage"
          },
          {
            "name": "edge_cases",
            "weight": 0.3,
            "measure": "branch_coverage"
          },
          {
            "name": "quality",
            "weight": 0.3,
            "measure": "mutation_score"
          }
        ]
      }
    },
    "selection_strategy": {
      "auto": true,
      "method": "weighted_score",
      "thresholds": {
        "auto_select_minimum": 0.75,
        "confidence_gap": 0.15
      },
      "fallback": {
        "enabled": true,
        "fallback_to": "claude",
        "on_tie": "prefer_faster"
      }
    },
    "history_tracking": {
      "enabled": true,
      "storage_path": "state/ai_benchmarks/",
      "retention_days": 90,
      "track_metrics": [
        "model",
        "task_type",
        "scores",
        "execution_time",
        "token_usage",
        "timestamp"
      ],
      "aggregation": {
        "period": "weekly",
        "metrics": [
          "avg_score",
          "success_rate",
          "avg_latency"
        ]
      }
    }
  },
  "dynamic_selection": {
    "enabled": true,
    "description": "Automatic selection of optimal AI model based on task characteristics",
    "criteria": {
      "task_type": {
        "weight": 0.4,
        "mapping": {
          "brainstorming": "gemini",
          "implementation": "claude",
          "refactoring": "codex",
          "testing": "codex",
          "research": "claude"
        }
      },
      "complexity": {
        "weight": 0.3,
        "levels": {
          "low": {
            "prefer": "haiku",
            "threshold": 100
          },
          "medium": {
            "prefer": "claude",
            "threshold": 500
          },
          "high": {
            "prefer": "claude",
            "threshold": null
          }
        }
      },
      "previous_performance": {
        "weight": 0.3,
        "lookback_period": 7,
        "min_samples": 3
      }
    },
    "override": {
      "user_preference": true,
      "stage_assignment": true
    }
  },
  "execution": {
    "parallel_benchmark": true,
    "max_concurrent_benchmarks": 2,
    "sample_tasks": {
      "enabled": true,
      "sample_size": 3,
      "sampling_method": "stratified"
    },
    "timeout": {
      "per_model": 300,
      "total": 900
    },
    "resource_limits": {
      "max_tokens_per_benchmark": 10000,
      "max_retries": 2
    }
  },
  "reporting": {
    "format": "markdown",
    "output_path": "state/ai_benchmarks/reports/",
    "include": [
      "summary_table",
      "metric_breakdown",
      "historical_comparison",
      "recommendation"
    ],
    "visualization": {
      "enabled": true,
      "charts": [
        "score_comparison_bar",
        "trend_line",
        "radar_chart"
      ]
    },
    "notifications": {
      "on_significant_change": {
        "threshold": 0.2,
        "channels": [
          "console",
          "handoff"
        ]
      }
    }
  },
  "integration": {
    "handoff": {
      "include_summary": true,
      "include_recommendation": true
    },
    "context_compression": {
      "preserve_recent": 3,
      "summarize_older": true
    }
  }
}